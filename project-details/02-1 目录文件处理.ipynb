{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596966135322",
   "display_name": "Python 3.5.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说明\n",
    "\n",
    "* 处理完数据就保存起来，然后把处理数据的代码注释掉\n",
    "* os相关函数：\n",
    "    * os.path\n",
    "    * os.listdir(dirname)  返回path目录下的文件夹和文件，但不包含子文件夹里的文件夹和文件数组\n",
    "    * os.walk   有三个结果，分布是文件夹路径、文件夹名称和文件名。 `for root,dirs,files in os.walk('data/images/')`\n",
    "    * os.scandir\n",
    "\n",
    "*  https://blog.csdn.net/happyjxt/article/details/51063854\n",
    "* https://blog.csdn.net/qq_39839807/article/details/104070761"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存路径\n",
    "```\n",
    "path = '10captcha/images/'\n",
    "num = 100 # 验证码图片数量\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 目录中的子文件操作`os.walk('data/images/')`\n",
    "* 获取文件名（经常文件名就是对应标签）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data/images/ ['子文件夹'] ['cat.jpg', 'dao2.jpg', 'Girl.jpg']\ndata/images/cat.jpg\ndata/images/dao2.jpg\ndata/images/Girl.jpg\ndata/images/子文件夹 [] []\n"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for root,dirs,files in os.walk('data/images/'): # 文件夹路径、文件夹名称和文件名数组\n",
    "    print(root,dirs,files)\n",
    "    for file in files:\n",
    "        print(os.path.join(root,file))\n",
    "        # image_path = os.path.join(root, file)\n",
    "        # print(image_path)\n",
    "        # img = Image.open(image_path)\n",
    "        # plt.imshow(img)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取url特定数据\n",
    "\n",
    "* 参考：https://github.com/HuangCongQing/TensorFlow/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6Tensorflow%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%BA%94%E7%94%A8/08-3%20inception-v3%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD%E5%B9%B6%E6%9F%A5%E7%9C%8B%E7%BB%93%E6%9E%84.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "inception-2015-12-05.tgz\ninception_model\\inception-2015-12-05.tgz\n"
    }
   ],
   "source": [
    "# inception模型下载\n",
    "inception_pretrain_model_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "# 模型存放地址\n",
    "inception_pretrain_model_dir = \"inception_model\"\n",
    "# 获取文件名以及文件路径\n",
    "filename = inception_pretrain_model_url.split('/')[-1]\n",
    "print(filename)\n",
    "filepath = os.path.join(inception_pretrain_model_dir,filename)\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取文件名为一个数组 `os.listdir(dataset_dir)`\n",
    "\n",
    "参考：https://github.com/HuangCongQing/TensorFlow/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6Tensorflow%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%BA%94%E7%94%A8/10-1%20%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB%5B%E5%AE%98%E6%96%B9%5D.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0131\ndata/code\\0131.jpg\n0153\ndata/code\\0153.jpg\n0161\ndata/code\\0161.jpg\n0178\ndata/code\\0178.jpg\n0398\ndata/code\\0398.jpg\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['data/code\\\\0131.jpg',\n 'data/code\\\\0153.jpg',\n 'data/code\\\\0161.jpg',\n 'data/code\\\\0178.jpg',\n 'data/code\\\\0398.jpg']"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "import os\n",
    "# 获取所以验证码图片\n",
    "def _get_filenames(dataset_dir):\n",
    "    captcha_names = []\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        # 获取文件路径\n",
    "        print(filename.split('.')[-2])\n",
    "        path = os.path.join(dataset_dir, filename)\n",
    "        print(path)\n",
    "        captcha_names.append(path)\n",
    "    return captcha_names\n",
    "\n",
    "dataset_dir = 'data/code'\n",
    "_get_filenames(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 已得文件数组，获取文件label \n",
    "* 获取文件名：`filename.split('/')[-1][:4]`\n",
    "\n",
    "参考：https://github.com/HuangCongQing/TensorFlow/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6Tensorflow%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%BA%94%E7%94%A8/10-1%20%E9%AA%8C%E8%AF%81%E7%A0%81%E8%AF%86%E5%88%AB%5B%E5%AE%98%E6%96%B9%5D.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n0 1 3 1\n1\n0 1 5 3\n2\n0 1 6 1\n3\n0 1 7 8\n4\n0 3 9 8\n['0131', '0153', '0161', '0178', '0398']\n"
    }
   ],
   "source": [
    "def _convert_dataset(split_name, filenames):\n",
    "    labelsAll = []\n",
    "    for i,filename in enumerate(filenames):\n",
    "        try:\n",
    "            # 拿到4位验证码并encode()\n",
    "            print(i)\n",
    "            labels = filename.split('/')[-1][:4]\n",
    "            labelsAll.append(labels)\n",
    "            # print(labelsAll)\n",
    "            # 生成protocal数据类型\n",
    "            print(int(labels[0]), int(labels[1]), int(labels[2]), int(labels[3]))\n",
    "        except IOError as e:\n",
    "            print('Wrong: ' + filename)\n",
    "            print('Error: ',e)\n",
    "            print('Skip it\\n')\n",
    "    return labelsAll\n",
    "\n",
    "\n",
    "# 运行函数\n",
    "filenames = ['data/code/0131.jpg',\n",
    " 'data/code/0153.jpg',\n",
    " 'data/code/0161.jpg',\n",
    " 'data/code/0178.jpg',\n",
    " 'data/code/0398.jpg']\n",
    "labelsAll = _convert_dataset('test', filenames)\n",
    "print(labelsAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 单文件中内容操作(每行  定位内容)\n",
    "参考：[使用inceptions...](https://github.com/HuangCongQing/TensorFlow/blob/master/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6Tensorflow%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%BA%94%E7%94%A8/08-4%20%E4%BD%BF%E7%94%A8inception-v3%E5%81%9A%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB.ipynb)\n",
    "\n",
    "* line.strip() 移除字符串首尾空格 \n",
    "* 检查字符串开头或结尾的一个简单方法是使用 str.startswith() 或者是 str.endswith() 方法\n",
    "\n",
    "\n",
    "### 加载文件2种方式\n",
    "第一种：f = open(dets_path, \"r+\")\n",
    "```\n",
    "\n",
    "f = open(dets_path, \"r+\")\n",
    "text = f.readlines()\n",
    "for line in text:\n",
    "```\n",
    "\n",
    "第二种：tf.gfile.GFile\n",
    "```\n",
    "\n",
    "proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "\n",
    "for line in proto_as_ascii:\n",
    "```\n",
    "\n",
    "### 加载下面两种文件\n",
    "\n",
    "文件：imagenet_synset_to_human_label_map.txt\n",
    "```\n",
    "n01440764    organism, being\n",
    "n01443537    benthos\n",
    "```\n",
    "文件：imagenet_2012_challenge_label_map_proto.pbtxt\n",
    "```\n",
    "entry {\n",
    "  target_class: 449\n",
    "  target_class_string: \"n01440764\"\n",
    "}\n",
    "entry {\n",
    "  target_class: 450\n",
    "  target_class_string: \"n01443537\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # 1.14\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeLookup(object):\n",
    "    def __init__(self):\n",
    "        label_lookup_path = 'inception_model/imagenet_2012_challenge_label_map_proto.pbtxt'\n",
    "        uid_lookup_path = 'inception_model/imagenet_synset_to_human_label_map.txt'\n",
    "        self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "        \n",
    "    def load(self, label_lookup_path, uid_lookup_path):\n",
    "        # 加载分类字符转n*******对应各分类名称的文件\n",
    "        '''\n",
    "        n01440764    organism, being\n",
    "        n01443537    benthos\n",
    "        '''\n",
    "        proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "        uid_to_human={}\n",
    "        # 一行一行读取数据\n",
    "        for line in proto_as_ascii_lines:\n",
    "            line = line.strip('\\n') # 去掉 \\n 回车键\n",
    "            parsed_items = line.split('\\t') # \\t是横向制表符，也就是一个tab键\n",
    "            uid = parsed_items[0] # n01440764\n",
    "            human_string = parsed_items[1] # organism, being\n",
    "            uid_to_human[uid] = human_string # uid_to_human[n01440764] = organism, being\n",
    "        print(uid_to_human)\n",
    "            \n",
    "        # 加载分类字符串n*******对应分类编号1-1000的文件\n",
    "        # tf.gfile.GFile(filename, mode)获取文本操作句柄，类似于python提供的文本操作open()函数，filename是要打开的文件名，mode是以何种方式去读写，将会返回一个文本操作句柄。\n",
    "        # line.strip() 移除字符串首尾空格 \n",
    "        # 检查字符串开头或结尾的一个简单方法是使用 str.startswith() 或者是 str.endswith() 方法。\n",
    "        '''\n",
    "        entry {\n",
    "            target_class: 449\n",
    "            target_class_string: \"n01440764\"\n",
    "        }\n",
    "        entry {\n",
    "            target_class: 450\n",
    "            target_class_string: \"n01443537\"\n",
    "        }'''\n",
    "        proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "        node_id_to_uid = {} # 字典\n",
    "        for line in proto_as_ascii: # # line.strip() 移除字符串首尾空格\n",
    "            if line.strip().startswith('target_class:'):# 寻找有target_class  \n",
    "                target_class = int(line.strip().split(':')[1])\n",
    "            elif line.strip().startswith('target_class_'):\n",
    "                target_class_string = line.strip().split(':')[1].strip()\n",
    "                node_id_to_uid[target_class] = target_class_string[1:-1] # node_id_to_uid[449] = n01440764\n",
    "        print(node_id_to_uid)\n",
    "\n",
    "\n",
    "        # 建立分类编号 1-1000 与对应分类名称的映射关系\n",
    "        node_id_to_name = {}\n",
    "        for key,val in node_id_to_uid.items(): # node_id_to_uid[449] = n01440764\n",
    "            name = uid_to_human[val]  # # uid_to_human[n01440764] = organism, being\n",
    "            node_id_to_name[key] = name\n",
    "        \n",
    "        return node_id_to_name # node_id_to_name[449] = organism, being\n",
    "    \n",
    "    # 传入分类编号1-1000 返回分类名称\n",
    "    def id_to_string(self, node_id):\n",
    "        if node_id not in self.node_lookup:\n",
    "            return ''\n",
    "        return self.node_lookup[node_id]\n",
    "\n",
    "# 引用class\n",
    "print('运行')\n",
    "node_lookup = NodeLookup()\n",
    "node_lookup.id_to_string(449)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理完数据就保存起来`np.save`，然后把处理数据的代码注释掉\n",
    "\n",
    "## 下面代码不用运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得训练用的wav文件路径列表 \n",
    "wav_files = get_wav_files(FLAGS.parent_dir,FLAGS.tr_sub_dirs)\n",
    "# 获取文件mfcc特征和对应标签\n",
    "tr_features,tr_labels = extract_features(wav_files)\n",
    "\n",
    "np.save('tr_features.npy',tr_features)\n",
    "np.save('tr_labels.npy',tr_labels)\n",
    "\n",
    "# tr_features=np.load('tr_features.npy')\n",
    "# tr_labels=np.load('tr_labels.npy')"
   ]
  }
 ]
}